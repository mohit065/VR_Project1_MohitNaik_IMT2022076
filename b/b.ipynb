{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Hyperparameters\n",
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Define transforms for the dataset (with augmentation)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Ensure compatibility with transforms\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Custom dataset loader to use OpenCV\n",
    "def cv2_loader(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    return image\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"../datasets/dataset1\"\n",
    "dataset = datasets.ImageFolder(root=os.path.join(dataset_path), transform=data_transforms, loader=cv2_loader)\n",
    "\n",
    "# Split dataset (85% train, 15% validation)\n",
    "train_size = int(0.85 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Load pretrained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 128),\n",
    "    nn.ReLU(),  # Activation function changed to ReLU\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)  # AdamW optimizer\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)  # Learning rate scheduler\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.float().to(device)\n",
    "        labels = labels.view(-1, 1)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_correct += ((outputs > 0.5).float() == labels).sum().item()\n",
    "    \n",
    "    train_acc = train_correct / train_size\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Validation\n",
    "torch.no_grad()\n",
    "model.eval()\n",
    "val_correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.float().to(device)\n",
    "        labels = labels.view(-1, 1)\n",
    "        outputs = model(images)\n",
    "        val_correct += ((outputs > 0.5).float() == labels).sum().item()\n",
    "\n",
    "val_acc = val_correct / val_size\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
