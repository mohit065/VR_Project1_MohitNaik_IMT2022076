{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Concatenate, Input,SeparableConv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 128,128\n",
    "NUM_IMAGES = 2000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "IMAGE_DIR = \"../datasets/dataset2/face_crop\"\n",
    "MASK_DIR = \"../datasets/dataset2/face_crop_segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_dir, mask_dir, img_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "\n",
    "    images, masks = [], []\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    mask_files = sorted(os.listdir(mask_dir))\n",
    "    count = 0\n",
    "\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        if(count>=NUM_IMAGES):\n",
    "            break\n",
    "\n",
    "        # Read images, resize and convert to grayscale\n",
    "        img = cv2.imread(os.path.join(image_dir, img_file))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, img_size) / 255.0\n",
    "\n",
    "        # Read masks, resize and convert to grayscale\n",
    "        mask = cv2.imread(os.path.join(mask_dir, mask_file), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, img_size)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        mask = mask / 255.0\n",
    "\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "        count+=1\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Load dataset\n",
    "X, Y = load_data(IMAGE_DIR, MASK_DIR)\n",
    "print(f\"Dataset loaded: {X.shape}, {Y.shape}\")\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = SeparableConv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    c2 = SeparableConv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    c3 = SeparableConv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    c4 = SeparableConv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "\n",
    "    # Decoder\n",
    "    u5 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(c4)\n",
    "    u5 = Concatenate()([u5, c3])\n",
    "    c5 = SeparableConv2D(128, (3, 3), activation='relu', padding='same')(u5)\n",
    "    u6 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(c5)\n",
    "    u6 = Concatenate()([u6, c2])\n",
    "    c6 = SeparableConv2D(64, (3, 3), activation='relu', padding='same')(u6)\n",
    "    u7 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(c6)\n",
    "    u7 = Concatenate()([u7, c1])\n",
    "    c7 = SeparableConv2D(32, (3, 3), activation='relu', padding='same')(u7)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the IoU and Dice metrics, and the Binary CrossEntropy + Dice Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-7)\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1e-7)\n",
    "\n",
    "# Define BCE + Dice Loss\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(y_true, y_pred) + 1 - dice(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model = unet()\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss=bce_dice_loss, metrics=[iou, dice])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate it for a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "def predict_sample(model, X_val, Y_val, index=70):\n",
    "    pred_mask = model.predict(np.expand_dims(X_val[index], axis=0))[0]\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(X_val[index])\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(Y_val[index].squeeze(), cmap=\"gray\")\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred_mask.squeeze(), cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.show()\n",
    "\n",
    "# Test model on a sample image\n",
    "predict_sample(model, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the validation IoU and Dice scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(y_true, y_pred, threshold=0.5):\n",
    "    if y_true.dtype != np.bool_:\n",
    "        y_true = y_true.astype(bool)\n",
    "    if y_pred.dtype != np.bool_:\n",
    "        y_pred = (y_pred > threshold).astype(bool)\n",
    "    intersection = np.logical_and(y_true, y_pred).sum()\n",
    "    union = np.logical_or(y_true, y_pred).sum()\n",
    "    if union == 0:\n",
    "        return 1.0\n",
    "    return intersection / union\n",
    "\n",
    "def calculate_dice(y_true, y_pred, threshold=0.5):\n",
    "    if y_true.dtype != np.bool_:\n",
    "        y_true = y_true.astype(bool)\n",
    "    if y_pred.dtype != np.bool_:\n",
    "        y_pred = (y_pred > threshold).astype(bool)\n",
    "    intersection = np.logical_and(y_true, y_pred).sum()\n",
    "    total = y_true.sum() + y_pred.sum()\n",
    "    if total == 0:\n",
    "        return 1.0\n",
    "    return 2 * intersection / total\n",
    "\n",
    "# Predict on validation set\n",
    "y_predicted = model.predict(X_val)\n",
    "\n",
    "# Compute IoU for each image\n",
    "iou_scores = []\n",
    "dice_scores = []\n",
    "for i in range(len(Y_val)):\n",
    "    iou = calculate_iou(Y_val[i], y_predicted[i])\n",
    "    dice = calculate_dice(Y_val[i], y_predicted[i])\n",
    "    iou_scores.append(iou)\n",
    "    dice_scores.append(dice)\n",
    "\n",
    "mean_iou = np.mean(iou_scores)\n",
    "mean_dice = np.mean(dice_scores)\n",
    "\n",
    "print(f\"\\nMean IoU on Validation Set: {mean_iou:.4f}\")\n",
    "print(f\"Mean Dice on Validation Set: {mean_dice:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
