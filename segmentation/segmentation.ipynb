{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import jaccard_score, f1_score\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up constants\n",
    "IMG_HEIGHT, IMG_WIDTH = 64, 64\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "IMAGE_DIR = \"../datasets/dataset2/1/face_crop\"\n",
    "MASK_DIR = \"../datasets/dataset2/1/face_crop_segmentation\"\n",
    "RESULTS_DIR = \"./results\"\n",
    "TRAIN_SIZE = 1000\n",
    "TEST_SIZE = 100\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Load and preprocess dataset\n",
    "def load_data(image_dir, mask_dir, img_size=(IMG_HEIGHT, IMG_WIDTH), limit=TRAIN_SIZE):\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    mask_files = sorted(os.listdir(mask_dir))\n",
    "    selected_indices = random.sample(range(len(image_files)), limit)\n",
    "    images, masks = [], []\n",
    "    for i in selected_indices:\n",
    "        img = cv2.imread(os.path.join(image_dir, image_files[i]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, img_size).astype(np.float32) / 255.0\n",
    "        mask = cv2.imread(os.path.join(mask_dir, mask_files[i]), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, img_size).astype(np.float32) / 255.0\n",
    "        mask = mask.reshape(img_size[0], img_size[1], 1)\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Load training and testing data\n",
    "X_train, Y_train = load_data(IMAGE_DIR, MASK_DIR, limit=TRAIN_SIZE)\n",
    "X_test, Y_test = load_data(IMAGE_DIR, MASK_DIR, limit=TEST_SIZE)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {Y_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {Y_test.shape}\")\n",
    "\n",
    "# Create TensorFlow dataset\n",
    "def create_dataset(X, Y):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.shuffle(len(X)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_dataset(X_train, Y_train)\n",
    "\n",
    "# U-Net Model\n",
    "def unet_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    def conv_block(x, filters):\n",
    "        x = tf.keras.layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = tf.keras.layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "        return x\n",
    "\n",
    "    def upsample_block(x, skip, filters):\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "        return conv_block(x, filters)\n",
    "\n",
    "    f = [64, 128, 256, 512, 1024]\n",
    "    c1 = conv_block(inputs, f[0])\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    c2 = conv_block(p1, f[1])\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    c3 = conv_block(p2, f[2])\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "    c4 = conv_block(p3, f[3])\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "    bottleneck = conv_block(p4, f[4])\n",
    "    u4 = upsample_block(bottleneck, c4, f[3])\n",
    "    u3 = upsample_block(u4, c3, f[2])\n",
    "    u2 = upsample_block(u3, c2, f[1])\n",
    "    u1 = upsample_block(u2, c1, f[0])\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='tanh')(u1)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Compile and train model\n",
    "model = unet_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss='binary_crossentropy')\n",
    "\n",
    "# Training loop (no validation metrics per epoch)\n",
    "for epoch in range(EPOCHS):\n",
    "    history = model.fit(train_dataset, epochs=1, verbose=1)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    # Compute training IoU and Dice scores\n",
    "    y_train_pred_bin = (y_train_pred.flatten() > 0.5).astype(np.uint8)\n",
    "    y_train_true_bin = (Y_train.flatten() > 0.5).astype(np.uint8)\n",
    "    train_iou = jaccard_score(y_train_true_bin, y_train_pred_bin, average='binary')\n",
    "    train_dice = f1_score(y_train_true_bin, y_train_pred_bin, average='binary')\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {history.history['loss'][-1]:.4f} - Train IoU: {train_iou:.4f} - Train Dice: {train_dice:.4f}\")\n",
    "\n",
    "# Final testing on 100 images\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute IoU and Dice scores for test set\n",
    "ious, dices = [], []\n",
    "\n",
    "for i in range(TEST_SIZE):\n",
    "    y_true_bin = (Y_test[i].flatten() > 0.5).astype(np.uint8)\n",
    "    y_pred_bin = (y_test_pred[i].flatten() > 0.5).astype(np.uint8)\n",
    "    \n",
    "    ious.append(jaccard_score(y_true_bin, y_pred_bin, average='binary'))\n",
    "    dices.append(f1_score(y_true_bin, y_pred_bin, average='binary'))\n",
    "\n",
    "# Print final evaluation metrics\n",
    "mean_iou = np.mean(ious)\n",
    "mean_dice = np.mean(dices)\n",
    "\n",
    "print(f\"\\nFinal Test Results on {TEST_SIZE} images:\")\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "print(f\"Mean Dice Score: {mean_dice:.4f}\")\n",
    "\n",
    "# Save & visualize 5 random test predictions\n",
    "sample_indices = random.sample(range(TEST_SIZE), 5)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    img = X_test[idx]\n",
    "    mask = Y_test[idx].squeeze()\n",
    "    pred_mask = y_test_pred[idx].squeeze()\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred_mask, cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    result_path = os.path.join(RESULTS_DIR, f\"test_result_{i+1}.png\")\n",
    "    plt.savefig(result_path)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Visualization results saved to {RESULTS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
